import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import firebase_admin
from firebase_admin import credentials, firestore
import re
from keybert import KeyBERT

def get_recommendations():
    # Initialize
    print("\n=====================================================")
    print("ðŸ”„ INITIALIZING RECOMMENDATION SYSTEM...")
    print("=====================================================")
    db = firestore.client()
    kw_model = KeyBERT()
    print("âœ… Successfully initialized Firestore DB and KeyBERT model")
    
    # Load data
    print("\n=====================================================")
    print("ðŸ“Š LOADING DATA FROM FIRESTORE...")
    print("=====================================================")
    df = pd.DataFrame([{
        'title': doc.to_dict().get('title', ''),
        'url': doc.to_dict().get('url', ''),
        'keywords': doc.to_dict().get('keywords', [])
    } for doc in db.collection('special_issues').stream()])
    print(f"âœ… Successfully loaded {len(df)} special issues from database")
    
    # Get user input
    print("\n=====================================================")
    print("ðŸ” COLLECTING USER PREFERENCES...")
    print("=====================================================")
    while True:
        keywords = input("\nEnter research interests (comma-separated): ").strip()
        if keywords and all(re.match(r'^[a-zA-Z0-9\s]+$', k.strip()) for k in keywords.split(',')):
            break
        print("Invalid! Use letters and numbers only")
    
    # Get recommendation count
    num_recs = 10
    try:
        user_input = input("\nEnter number of recommendations (default: 10): ").strip()
        if user_input:
            num_recs = max(1, int(user_input))
    except ValueError:
        pass
    print(f"âœ… User requested {num_recs} recommendations")
    
    # Enhance keywords
    print("\n=====================================================")
    print("ðŸ§  ENHANCING USER KEYWORDS...")
    print("=====================================================")
    print(f"ðŸ“Œ Original keywords: {keywords}")
    user_keywords = [k.strip() for k in keywords.split(',')]
    enhanced_user_keywords = user_keywords + [
        kw for kw, _ in kw_model.extract_keywords(' '.join(user_keywords), top_n=3) 
        if kw not in user_keywords
    ]
    print(f"âœ… Enhanced search keywords: {', '.join(enhanced_user_keywords)}")
    
    # Enhance document keywords
    print("\n=====================================================")
    print("ðŸ”„ ENHANCING DOCUMENT KEYWORDS...")
    print("=====================================================")
    keyword_count_before = sum(len(kw) for kw in df['keywords'])
    print(f"ðŸ“Š Total keywords before enhancement: {keyword_count_before}")
    
    for i, row in df.iterrows():
        if row['keywords']:
            doc_text = row['title'] + ' ' + ' '.join(row['keywords'])
            new_keywords = [kw for kw, _ in kw_model.extract_keywords(doc_text, top_n=3)
                          if kw not in row['keywords']]
            df.at[i, 'keywords'] = row['keywords'] + new_keywords
    
    keyword_count_after = sum(len(kw) for kw in df['keywords'])
    print(f"âœ… Total keywords after enhancement: {keyword_count_after}")
    print(f"âœ… Added {keyword_count_after - keyword_count_before} new keywords")
    
    # Calculate similarities
    print("\n=====================================================")
    print("ðŸ§® CALCULATING SIMILARITY SCORES...")
    print("=====================================================")
    df['keywords_text'] = df['keywords'].apply(lambda x: ' '.join(x))
    corpus = [' '.join(enhanced_user_keywords)] + df['keywords_text'].tolist()
    
    print("ðŸ“Š Creating document vectors...")
    vectorizer = CountVectorizer()
    vector_matrix = vectorizer.fit_transform(corpus)
    print(f"âœ… Vector matrix created with shape: {vector_matrix.shape}")
    
    print("ðŸ“Š Computing cosine similarities...")
    similarity_scores = cosine_similarity(vector_matrix)[0, 1:].flatten()
    df['similarity_score'] = similarity_scores
    print(f"âœ… Similarity calculation complete")
    
    # Sort and prepare results
    print("\n=====================================================")
    print("ðŸ“‹ PREPARING FINAL RECOMMENDATIONS...")
    print("=====================================================")
    sorted_results = df.sort_values('similarity_score', ascending=False).head(num_recs)
    print(f"âœ… Sorted {len(df)} items by relevance")
    print(f"âœ… Selected top {num_recs} matches")
    
    # Display results
    print("\n=====================================================")
    print(f"ðŸ† TOP {num_recs} RECOMMENDATIONS:")
    print("=====================================================")
    for idx, (_, row) in enumerate(sorted_results.iterrows(), 1):
        keywords_display = ', '.join(row['keywords'][:5])
        if len(row['keywords']) > 5:
            keywords_display += f" (+ {len(row['keywords']) - 5} more)"
        
        print(f"\n{idx}. {row['title']}")
        print(f"   Score: {row['similarity_score']:.2%}")
        print(f"   URL: {row['url']}")
        print(f"   Keywords: {keywords_display}")
    
    print("\n=====================================================")
    print("âœ… RECOMMENDATION PROCESS COMPLETE")
    print("=====================================================")

if __name__ == "__main__":
    print("\n=====================================================")
    print("ðŸš€ STARTING SPECIAL ISSUES RECOMMENDER")
    print("=====================================================")
    print("ðŸ”‘ Initializing Firebase connection...")
    firebase_admin.initialize_app(credentials.Certificate('special-issues-project-firebase-adminsdk-fbsvc-0b2060ce4b.json'))
    print("âœ… Firebase connection established")
    get_recommendations()